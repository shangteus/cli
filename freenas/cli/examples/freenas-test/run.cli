#
# Top-level test runner.  Source this file to run all of the tests, behavior
# which can be optionally overridden by setting TEST_SET below to your own
# value.

TEST_SET = [ \
    "disk", "volume", "network", "service", "system", "account", "share", "boot", \
    "peering", "session", "task", "alert", "calendar", "tunable", "vm", "docker" \
]

# Cause the tests to exit upon any error.
if (not defined("_exit_on_error")) {
	_exit_on_error="no"
}

# Set _batch=yes external to this script if you don't want it to ask any
# questions and simply run all tests by default.
if (not defined("_batch")) {
	_batch="no"
}

# Where to run all of these scripts from.
const TOP_DIR = ${cli_src_path+"/examples/freenas-test/"}

# Set this to yes if you want to run the more stressy-tests
test_me_harder=true

# Where to log test result output to
if (not defined("output_file")) {
   output_file="output-log.txt"
}
output_handle = fopen(output_file, "w");
maybe_die(_success, "main#1", "Unable to open log file " + output_file + " for writing")

# Don't be verbose by default.
setopt verbosity=0

# Some constants which will be shared across tests, hence "global" in scope.
# They do not have underscores prepended to their names to designate them
# as such.
const TEST_USER = "mytestuser"
const TEST_GROUP = "mytestgroup"
const VOL_NAME = "test_tank"
VOL_OBJECT = null
SYS_DATASET_VOL = null

source ${TOP_DIR + "common_funcs.cli"}

# Set some sensible default options before beginning the test run
setopt rollbar_enabled=no

function test_and_set_sentinel() {
	if (test_sentinel()) {
		print("These tests are already running; please only run one copy")
		print("at a time.  If this is in error, run the clear_sentinel()")
		print("function by hand to clear this condition.")
		return true
	} else {
		set_sentinel()
		return false
	}
}

function load_all() {
	 for (test in TEST_SET) {
	 	_path=${TOP_DIR + test + ".cli"}
		print(">> Loading " + _path)
		source ${_path}
		if (_success != true) {
			print(_path + " test script not found")
			remove(TEST_SET, test)
		}
	}
}

# Run all of the create functions.
function create_all() {
	if (test_and_set_sentinel() == false) {
	    setopt abort_on_errors=yes
	    for (test in TEST_SET) {
		eval(test + "_create()")
		if (test_me_harder == true) {
		   eval(test + "_hard_create()")
		}
	    }
	    clear_sentinel()
	}
}

# Run all of the destroy (cleanup) functions.
function destroy_all() {
	if (test_and_set_sentinel() == false) {
	    setopt abort_on_errors=no
	    for (i = length(TEST_SET) - 1; i >= 0; i = i - 1) {
		if (test_me_harder == true) {
		   eval(TEST_SET[i] + "_hard_destroy()")
		}
		eval(TEST_SET[i] + "_destroy()")
	    }
	    clear_sentinel()
	}
}

function run_all() {
	if (_batch == "yes") {
		x="yes"
	} else {
		x = readline("All tests loaded. Ready to run them? ([y] / n) ")
	}
	if (x == "yes" or x == "y" or x == "") {
		if (_batch == "yes") {
			x="yes"
		} else {
			x = readline("Also run stress tests? ([y] or n) ")
		}
		test_me_harder = (x == "yes" or x == "y" or x == "")
		print(">>> Also logging results to " + output_file)
		create_all()
		destroy_all()
		fclose(output_handle)
	} else {
		print("You can run the tests yourself by calling create_all()")
		print("or testname_create() then destroy_all() or testname_destroy()")
	}
}

# OK do it.
load_all()
run_all()
